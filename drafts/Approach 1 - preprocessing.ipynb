{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг\n",
    "**Задачи:**\n",
    "* ✔ имплементировать правила замены букв и буквосочетаний\n",
    "* ✔ скомпилировать словари матерных, грубых и ругательных слов\n",
    "* имплементировать замену по расстоянию Левенштейна и словарю\n",
    "* ✔ собрать оба подхода в двухступенчатый алгоритм\n",
    "\n",
    "Ссылки на использованные словари:  \n",
    "https://gist.github.com/nestyme/8531fe4ec34cd2c8e9b306513cb8b59a (Zueva et al.) 89 слов  \n",
    "https://github.com/bohdan1/AbusiveLanguageDataset/blob/master/bad_words.txt (Andrusyak et al.) 623 слова  \n",
    "Из первого были удалены слова, не относящиеся к ругательным, из второго - повторы, имеющиеся в первом\n",
    "\n",
    "### Преколы и вопросы:\n",
    "* в словаре Андрусяка некоторые слова даны в разных сиклонениях и в разных в т.ч. искажённых написаниях. Удалить для чистоты эксперимента?\n",
    "* что делать с леммами\n",
    "* в словаре пайморфи некоторые искажённые формы существуют (*кули*, *мля*). Возможно, есть смысл не делать проверку на существование и выполнять замены везде"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замена букв по правилам\n",
    "1. ✔ Взять слово, не содержащее пунктуацию\n",
    "2. ✔ Проверить, существует ли слово\n",
    "3. ✔ Если нет, то заменить по очереди все пары букв и буквосочетаний по очереди  \n",
    "    (именно буквосочетаний и по очереди, потому что в слове *ипать* заменить надо *ип-еб*, а не *и-е*, *п-б*, *а-о* по очереди или разом)  \n",
    "4. ✔ Сравнить, если ли в словаре ругательств полученный результат. Если да, заменить на него\n",
    "5. ✔ Если результат не нашёлся, проверить все возможные комбинации одновременных замен\n",
    "6. ✔ Если не нашлось и так, то вернуть исходное слово\n",
    "\n",
    "\n",
    "### Расстояние Левенштейна до словаря мата\n",
    "1. ✔ Взять слово, содержащее некириллические символы\n",
    "2. ✔  Посчитать регуляркой их количество n\n",
    "3. Найти расстояния Левенштейна m1, ..., mn до каждого из слов в словаре ругательств\n",
    "4. Если n == m, то это корректная форма искомого слова  \n",
    "Если нет n == m, то брать слово с минимальным m. На случай, если пропущено несколько букв или одна буква заменена несколькими символами  \n",
    "5. Заменить слово на это\n",
    "\n",
    "\n",
    "#### Правила замены:\n",
    "йо → ё  \n",
    "^мл → бл  \n",
    "ип → еб  \n",
    "п → б  \n",
    "к → х  \n",
    "т → д  \n",
    "а → о  \n",
    "с → з  \n",
    "и → е  \n",
    "\n",
    "к → г  \n",
    "ш → ж  \n",
    "ф → в  \n",
    "3.14 → пи  \n",
    "3,14 → пи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import enchant\n",
    "import itertools\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'ипать йобаный ибать епать гавно гавном мля кули 3.14дор'\n",
    "bad_wordlist = ['ебать', 'ёбаный', 'ебаный', 'говно', 'бля', 'хули', 'пидор']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потом можно удалить из кода и оставить только в файле\n",
    "replace_dict = {'йо': 'ё', \n",
    "                'ип': 'еб',\n",
    "                'мл': 'бл',\n",
    "                'ау': 'ов',\n",
    "                'и': 'е',\n",
    "                'п': 'б',\n",
    "                'т': 'д',\n",
    "                'к': 'х',\n",
    "                'а': 'о',\n",
    "                'с': 'з',\n",
    "                'ш': 'ж',\n",
    "                'ф': 'в',\n",
    "                'у': 'в',\n",
    "                '3.14': 'пи',\n",
    "                '3,14': 'пи'}\n",
    "with open('replacement.json', 'w') as f:\n",
    "    json.dump(replace_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('replacement.json', 'r') as f:\n",
    "    replace_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Собирание замены букв по правилам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonletter_pat = re.compile('[^а-яёА-ЯЁ]')\n",
    "pi_pat = re.compile('^3[.,]14.+')\n",
    "\n",
    "def contains_nonletters(word):\n",
    "    '''\n",
    "    returns True, if given word contains any character that is not a cyrillic letter or\n",
    "    \"3.14\" / \"3,14\" sequence\n",
    "    '''\n",
    "    if bool(re.search(nonletter_pat, word)) and not bool(re.search(pi_pat, word)):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_exists(word):\n",
    "    '''\n",
    "    checks whether given word is in OpenCorpora dictionary using PyMorphy2\n",
    "    '''\n",
    "    if morph.word_is_known(word):\n",
    "        # return True\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_by_letters(word):\n",
    "    '''\n",
    "    takes a word, replaces letters one pair at a time unless the result or its lemma is\n",
    "    found in the bad dictionary, otherwise returns the intial word\n",
    "    '''\n",
    "    for old, new in replace_dict.items():\n",
    "        if old in word:\n",
    "            new_word = word.replace(old, new)\n",
    "            if morph.parse(new_word)[0].normal_form in bad_wordlist or new_word in bad_wordlist:\n",
    "                return new_word\n",
    "    # if the word is not found, go through all possible combinations of rules\n",
    "    for l in range(1, len(replace_dict)):\n",
    "        for tple in itertools.combinations(replace_dict.keys(), l+1):\n",
    "            new_word = word\n",
    "            for key in tple:\n",
    "                new_word = new_word.replace(key, replace_dict[key])\n",
    "        if morph.parse(new_word)[0].normal_form in bad_wordlist or new_word in bad_wordlist:\n",
    "            return new_word\n",
    "    # if still not found, return the initial input\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Собирание Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonletter_pat = re.compile('[^а-яёА-ЯЁ]')\n",
    "\n",
    "def count_nonletters(word):\n",
    "    return len(re.findall(nonletter_pat, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(count_nonletters('с00ба)ка)'))\n",
    "print(count_nonletters('б***'))\n",
    "print(count_nonletters('пи3дец'))\n",
    "print(count_nonletters('собака'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальная функция:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_distortion(text, debug=False):\n",
    "    '''\n",
    "    converts text to lowercase and performs all steps of checks and corrections for each token\n",
    "    '''\n",
    "    new_text = text.lower().split()\n",
    "    \n",
    "    for i, token in enumerate(new_text):\n",
    "        if not contains_nonletters(token): # skip token if it has non-cyrillic characters\n",
    "            if not word_exists(token): # skip token if it is an existing word\n",
    "                if debug:\n",
    "                    print(correct_by_letters(token))\n",
    "                new_text[i] = correct_by_letters(token)\n",
    "\n",
    "        else: # it has non-cyrillic characters and therefore is passed to Levenstein\n",
    "            #new_text[i] = correct_by_levenstein(token) \n",
    "            pass\n",
    "        \n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ипать йобаный ибать епать гавно гавном мля кули 3.14дор 3,14тар алаоааллдлдлдв собака\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ебать ёбаный ебать ебать говно говном бля хули пидор пидор алаоааллдлдлдв собака'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = 'ипать йобаный ибать епать гавно гавном мля кули 3.14дор 3,14тар алаоааллдлдлдв собака'\n",
    "print(test_string)\n",
    "preprocess_distortion(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "## туду: расстояние левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
